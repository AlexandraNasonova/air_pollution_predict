{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb00314d",
   "metadata": {},
   "source": [
    "Данный ноутбук содержит код для создания категориальных и lag-фичей, подготовки данных к последующему этапу ML и собственно эксперименты ML c моделью линейной регрессии и моделью Catboost на основе timeseries полученного для станции STA-DK0034A Дании."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c799c3",
   "metadata": {},
   "source": [
    "<a id='part_0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a1f33",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "### [1.Подготовка данных к ML](#part_1)\n",
    "### [2.Эксперименты с моделями линейной регрессии](#part_2)\n",
    "### [3.Эксперименты с Catboost](#part_3)\n",
    "### [4.Обсуждение и выводы](#part_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7703d8ea",
   "metadata": {},
   "source": [
    "<a id='part_1'></a>\n",
    "## 1.Подготовка данных к ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0444c229",
   "metadata": {},
   "source": [
    "[ВЕРНУТЬСЯ В НАЧАЛО](#part_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6245377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9a8686",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load previously created final AQI timeseries for 'STA-DK0034A' station in Denmark\n",
    "\n",
    "ts_final = pd.read_csv('ts_final_dk.csv', low_memory=False)\n",
    "ts_final['DatetimeEnd'] = pd.to_datetime(ts_final['DatetimeEnd'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "ts_final = ts_final.set_index('DatetimeEnd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0cb66af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DatetimeEnd</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:00:00+01:00</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02 00:00:00+01:00</th>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03 00:00:00+01:00</th>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04 00:00:00+01:00</th>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05 00:00:00+01:00</th>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            aqi\n",
       "DatetimeEnd                    \n",
       "2013-01-01 00:00:00+01:00  21.0\n",
       "2013-01-02 00:00:00+01:00  41.0\n",
       "2013-01-03 00:00:00+01:00  39.0\n",
       "2013-01-04 00:00:00+01:00  48.0\n",
       "2013-01-05 00:00:00+01:00  33.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check that ts_final is in a proper timeseries format\n",
    "\n",
    "ts_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a20b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions to generate categorical and lag-features\n",
    "\n",
    "def feature_creator_v1(df_temp,number_of_lag_features=10): # Generate only numeric features\n",
    "    df = df_temp.copy()\n",
    "    df.columns = ['aqi_d0']\n",
    "    n_features = int(number_of_lag_features)\n",
    "    current_column_name = 'aqi_d0'\n",
    "    prev_column_name = 'aqi_d0'\n",
    "    iternum = 1\n",
    "    for i in range(n_features):\n",
    "        current_column_name = current_column_name[:5] + str(iternum)\n",
    "        df[current_column_name] = df[prev_column_name].shift(1)\n",
    "        iternum +=1\n",
    "        prev_column_name = current_column_name\n",
    "    return df\n",
    "\n",
    "def feature_creator_v2(df_temp,number_of_lag_features=10): # Generate both categorical and numeric features\n",
    "    df = df_temp.copy()\n",
    "    df.columns = ['aqi_d0']\n",
    "    df['month'] = df.index.month\n",
    "    df['monthday'] = df.index.strftime(\"%d\")\n",
    "    df['weekday'] = df.index.weekday\n",
    "    weekdays_list = list(df[\"weekday\"])\n",
    "    weekend_list = []\n",
    "    for i in range(len(weekdays_list)):\n",
    "        weekend_flag = False\n",
    "        if (weekdays_list[i] == 6) | (weekdays_list[i] == 0):\n",
    "            weekend_flag = True\n",
    "        weekend_list.append(weekend_flag)\n",
    "    df['weekend'] = weekend_list\n",
    "    n_features = int(number_of_lag_features)\n",
    "    current_column_name = 'aqi_d0'\n",
    "    prev_column_name = 'aqi_d0'\n",
    "    iternum = 1\n",
    "    for i in range(n_features):\n",
    "        current_column_name = current_column_name[:5] + str(iternum)\n",
    "        df[current_column_name] = df[prev_column_name].shift(1)\n",
    "        iternum +=1\n",
    "        prev_column_name = current_column_name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64625a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aqi_d0</th>\n",
       "      <th>aqi_d1</th>\n",
       "      <th>aqi_d2</th>\n",
       "      <th>aqi_d3</th>\n",
       "      <th>aqi_d4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DatetimeEnd</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-26 00:00:00+01:00</th>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-27 00:00:00+01:00</th>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 00:00:00+01:00</th>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 00:00:00+01:00</th>\n",
       "      <td>35.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-30 00:00:00+01:00</th>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           aqi_d0  aqi_d1  aqi_d2  aqi_d3  aqi_d4\n",
       "DatetimeEnd                                                      \n",
       "2022-10-26 00:00:00+01:00    33.0    32.0    22.0    18.0    24.0\n",
       "2022-10-27 00:00:00+01:00    37.0    33.0    32.0    22.0    18.0\n",
       "2022-10-28 00:00:00+01:00    43.0    37.0    33.0    32.0    22.0\n",
       "2022-10-29 00:00:00+01:00    35.0    43.0    37.0    33.0    32.0\n",
       "2022-10-30 00:00:00+01:00    34.0    35.0    43.0    37.0    33.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aqi_d0</th>\n",
       "      <th>month</th>\n",
       "      <th>monthday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>aqi_d1</th>\n",
       "      <th>aqi_d2</th>\n",
       "      <th>aqi_d3</th>\n",
       "      <th>aqi_d4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DatetimeEnd</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-26 00:00:00+01:00</th>\n",
       "      <td>33.0</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-27 00:00:00+01:00</th>\n",
       "      <td>37.0</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 00:00:00+01:00</th>\n",
       "      <td>43.0</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-29 00:00:00+01:00</th>\n",
       "      <td>35.0</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-30 00:00:00+01:00</th>\n",
       "      <td>34.0</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>35.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           aqi_d0  month monthday  weekday  weekend  aqi_d1  \\\n",
       "DatetimeEnd                                                                   \n",
       "2022-10-26 00:00:00+01:00    33.0     10       26        2    False    32.0   \n",
       "2022-10-27 00:00:00+01:00    37.0     10       27        3    False    33.0   \n",
       "2022-10-28 00:00:00+01:00    43.0     10       28        4    False    37.0   \n",
       "2022-10-29 00:00:00+01:00    35.0     10       29        5    False    43.0   \n",
       "2022-10-30 00:00:00+01:00    34.0     10       30        6     True    35.0   \n",
       "\n",
       "                           aqi_d2  aqi_d3  aqi_d4  \n",
       "DatetimeEnd                                        \n",
       "2022-10-26 00:00:00+01:00    22.0    18.0    24.0  \n",
       "2022-10-27 00:00:00+01:00    32.0    22.0    18.0  \n",
       "2022-10-28 00:00:00+01:00    33.0    32.0    22.0  \n",
       "2022-10-29 00:00:00+01:00    37.0    33.0    32.0  \n",
       "2022-10-30 00:00:00+01:00    43.0    37.0    33.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Check feature creators to make sure they work as expected\n",
    "\n",
    "tsf1 = feature_creator_v1(ts_final, 4)\n",
    "tsf2 = feature_creator_v2(ts_final, 4)\n",
    "display(tsf1.tail())\n",
    "display(tsf2.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c46ad364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3590"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3590"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Create 2 datasets; one with 10 lag-features, another with 30 lag-features\n",
    "\n",
    "tsf10 = feature_creator_v1(ts_final, 10)\n",
    "tsf30 = feature_creator_v1(ts_final, 30)\n",
    "display(len(tsf10))\n",
    "display(len(tsf30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35a1979",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Truncate first 30 rows of created datasets to remove rows containing NaN values\n",
    "\n",
    "tsf10 = tsf10.iloc[30:,:]\n",
    "tsf30 = tsf30.iloc[30:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9892d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3560"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3560"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Verify that we truncated exactly 30 rows\n",
    "\n",
    "display(len(tsf10))\n",
    "display(len(tsf30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c192e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to split dataset into train and test parts\n",
    "\n",
    "def data_splitter(df_temp):\n",
    "    df = df_temp\n",
    "    df_train = df[df.index < \"2022-01-01 00:00:00+01:00\"].copy()\n",
    "    df_test = df[df.index >= \"2022-01-01 00:00:00+01:00\"].copy()\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "### Function to split dataset into train and test parts v2\n",
    "\n",
    "def data_splitter_v2(df_temp):\n",
    "    df = df_temp\n",
    "    df_train = df[df.index < \"2021-10-01 00:00:00+01:00\"].copy()\n",
    "    df_test = df[df.index >= \"2021-10-01 00:00:00+01:00\"].copy()\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d692ee",
   "metadata": {},
   "source": [
    "<a id='part_2'></a>\n",
    "## 2.Эксперименты с моделями линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ee2aa",
   "metadata": {},
   "source": [
    "[ВЕРНУТЬСЯ В НАЧАЛО](#part_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4a4a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply previously created function to our datasets\n",
    "\n",
    "df_train10, df_test10 = data_splitter(tsf10)\n",
    "df_train30, df_test30 = data_splitter(tsf30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ca14bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split datasets further into X(features) and y(target) components\n",
    "\n",
    "columns_to_drop = ['aqi_d0']\n",
    "\n",
    "y_train10 = df_train10['aqi_d0']\n",
    "X_train10 = df_train10.drop(columns_to_drop, axis=1)\n",
    "y_test10 = df_test10['aqi_d0']\n",
    "X_test10 = df_test10.drop(columns_to_drop, axis=1)\n",
    "\n",
    "y_train30 = df_train30['aqi_d0']\n",
    "X_train30 = df_train30.drop(columns_to_drop, axis=1)\n",
    "y_test30 = df_test30['aqi_d0']\n",
    "X_test30 = df_test30.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9827e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5db395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for TRAIN:\n",
      "MSE: 94.32011222958425\n",
      "R2: 0.40597959933723293\n",
      "for TEST:\n",
      "MSE: 59.3182458129779\n",
      "R2: 0.28025522634722955\n"
     ]
    }
   ],
   "source": [
    "### Standard linear regression with 10 features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train10)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train10)\n",
    "X_test_scaled = scaler.transform(X_test10)\n",
    "\n",
    "lr_scaled = LinearRegression()\n",
    "lr_scaled.fit(X_train_scaled, y_train10)\n",
    "pred_train10 = lr_scaled.predict(X_train_scaled)\n",
    "pred_test10 = lr_scaled.predict(X_test_scaled)\n",
    "\n",
    "print('for TRAIN:')\n",
    "print('MSE:', MSE(y_train10, pred_train10))\n",
    "print('R2:', r2_score(y_train10, pred_train10))\n",
    "print('for TEST:')\n",
    "print('MSE:', MSE(y_test10, pred_test10))\n",
    "print('R2:', r2_score(y_test10, pred_test10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b32ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross-validation for linear regression with 10 numeric features\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 10)\n",
    "rmse = []\n",
    "mae = []\n",
    "r2 = []\n",
    "rmse_dfm = []\n",
    "mae_dfm = []\n",
    "r2_dfm = []\n",
    "all_predictions = None\n",
    "aqi_mean = tsf10['aqi_d0'].mean()\n",
    "for train_index, test_index in tscv.split(tsf10):\n",
    "    cv_train, cv_test = tsf10.iloc[train_index], tsf10.iloc[test_index]\n",
    "    \n",
    "    y_cv_train = cv_train['aqi_d0']\n",
    "    X_cv_train = cv_train.drop('aqi_d0', axis=1)\n",
    "    y_cv_test = cv_test['aqi_d0']\n",
    "    X_cv_test = cv_test.drop('aqi_d0', axis=1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_cv_train)\n",
    "    \n",
    "    X_cv_train_scaled = scaler.transform(X_cv_train)\n",
    "    X_cv_test_scaled = scaler.transform(X_cv_test)\n",
    "    \n",
    "    lr_scaled = LinearRegression()\n",
    "    lr_scaled.fit(X_cv_train_scaled, y_cv_train )\n",
    "    predictions = lr_scaled.predict(X_cv_test_scaled)\n",
    " \n",
    "    rmse.append(np.sqrt(MSE(y_cv_test, predictions)))\n",
    "    mae.append(MAE(y_cv_test, predictions))\n",
    "    r2.append(r2_score(y_cv_test, predictions))\n",
    "\n",
    "    dfmean = pd.DataFrame(index=cv_test.index)\n",
    "    dfmean['aqi_d0'] = aqi_mean\n",
    "    \n",
    "    rmse_dfm.append(np.sqrt(MSE(y_cv_test, dfmean.values)))\n",
    "    mae_dfm.append(MAE(y_cv_test, dfmean.values))\n",
    "    r2_dfm.append(r2_score(y_cv_test, dfmean.values))\n",
    "\n",
    "\n",
    "rmse_df_mean = np.mean(rmse_dfm)\n",
    "rmse_mean = np.mean(rmse)\n",
    "\n",
    "mae_df_mean = np.mean(mae_dfm)\n",
    "mae_mean = np.mean(mae)\n",
    "\n",
    "r2_df_mean = np.mean(r2_dfm)\n",
    "r2_mean = np.mean(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ab0b723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean baseline:\n",
      "RMSE: 12.259450105194293\n",
      "MAE: 8.964555605802344\n",
      "R2 -0.06014788401808879\n",
      "\n",
      "Linear regression with 10 lag-features:\n",
      "RMSE: 9.604746175563356\n",
      "MAE: 6.996398468789235\n",
      "R2 0.3482510123808328\n"
     ]
    }
   ],
   "source": [
    "print('Mean baseline:')\n",
    "print('RMSE:', rmse_df_mean)\n",
    "print('MAE:', mae_df_mean)\n",
    "print('R2', r2_df_mean)\n",
    "print('')\n",
    "print('Linear regression with 10 lag-features:')\n",
    "print('RMSE:', rmse_mean)\n",
    "print('MAE:', mae_mean)\n",
    "print('R2', r2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2492cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for TRAIN:\n",
      "MSE: 93.31503263325668\n",
      "R2: 0.4123095089439479\n",
      "for TEST:\n",
      "MSE: 59.16578889665561\n",
      "R2: 0.2821050799163345\n"
     ]
    }
   ],
   "source": [
    "### Standard linear regression with 30 features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train30)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train30)\n",
    "X_test_scaled = scaler.transform(X_test30)\n",
    "\n",
    "lr_scaled = LinearRegression()\n",
    "lr_scaled.fit(X_train_scaled, y_train30)\n",
    "pred_train30 = lr_scaled.predict(X_train_scaled)\n",
    "pred_test30 = lr_scaled.predict(X_test_scaled)\n",
    "\n",
    "print('for TRAIN:')\n",
    "print('MSE:', MSE(y_train30, pred_train30))\n",
    "print('R2:', r2_score(y_train30, pred_train30))\n",
    "print('for TEST:')\n",
    "print('MSE:', MSE(y_test30, pred_test30))\n",
    "print('R2:', r2_score(y_test30, pred_test30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57675ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross-validation for linear regression with 30 numeric features\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 10)\n",
    "rmse = []\n",
    "mae = []\n",
    "r2 = []\n",
    "rmse_dfm = []\n",
    "mae_dfm = []\n",
    "r2_dfm = []\n",
    "all_predictions = None\n",
    "aqi_mean = tsf30['aqi_d0'].mean()\n",
    "for train_index, test_index in tscv.split(tsf30):\n",
    "    cv_train, cv_test = tsf30.iloc[train_index], tsf30.iloc[test_index]\n",
    "    \n",
    "    y_cv_train = cv_train['aqi_d0']\n",
    "    X_cv_train = cv_train.drop('aqi_d0', axis=1)\n",
    "    y_cv_test = cv_test['aqi_d0']\n",
    "    X_cv_test = cv_test.drop('aqi_d0', axis=1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_cv_train)\n",
    "    \n",
    "    X_cv_train_scaled = scaler.transform(X_cv_train)\n",
    "    X_cv_test_scaled = scaler.transform(X_cv_test)\n",
    "    \n",
    "    lr_scaled = LinearRegression()\n",
    "    lr_scaled.fit(X_cv_train_scaled, y_cv_train )\n",
    "    predictions = lr_scaled.predict(X_cv_test_scaled)\n",
    " \n",
    "    rmse.append(np.sqrt(MSE(y_cv_test, predictions)))\n",
    "    mae.append(MAE(y_cv_test, predictions))\n",
    "    r2.append(r2_score(y_cv_test, predictions))\n",
    "\n",
    "    dfmean = pd.DataFrame(index=cv_test.index)\n",
    "    dfmean['aqi_d0'] = aqi_mean\n",
    "    \n",
    "    rmse_dfm.append(np.sqrt(MSE(y_cv_test, dfmean.values)))\n",
    "    mae_dfm.append(MAE(y_cv_test, dfmean.values))\n",
    "    r2_dfm.append(r2_score(y_cv_test, dfmean.values))\n",
    "\n",
    "\n",
    "rmse_df_mean = np.mean(rmse_dfm)\n",
    "rmse_mean = np.mean(rmse)\n",
    "\n",
    "mae_df_mean = np.mean(mae_dfm)\n",
    "mae_mean = np.mean(mae)\n",
    "\n",
    "r2_df_mean = np.mean(r2_dfm)\n",
    "r2_mean = np.mean(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eab7c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean baseline:\n",
      "RMSE: 12.259450105194293\n",
      "MAE: 8.964555605802344\n",
      "R2 -0.06014788401808879\n",
      "\n",
      "Linear regression with 30 lag-features:\n",
      "RMSE: 9.669484518164268\n",
      "MAE: 7.033486317492153\n",
      "R2 0.33962362863053464\n"
     ]
    }
   ],
   "source": [
    "print('Mean baseline:')\n",
    "print('RMSE:', rmse_df_mean)\n",
    "print('MAE:', mae_df_mean)\n",
    "print('R2', r2_df_mean)\n",
    "print('')\n",
    "print('Linear regression with 30 lag-features:')\n",
    "print('RMSE:', rmse_mean)\n",
    "print('MAE:', mae_mean)\n",
    "print('R2', r2_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b3a03",
   "metadata": {},
   "source": [
    "Как при использовании 10, так и при использовании 30 предыдущих индексов AQI, получаются одинаково плохие результаты. Посмотрим что будет при использовании 100 предыдущих значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b2bb2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for TRAIN:\n",
      "MSE: 89.96312397206802\n",
      "R2: 0.4285474809910045\n",
      "for TEST:\n",
      "MSE: 61.105824230204\n",
      "R2: 0.25856543755358496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mint\\AppData\\Local\\Temp\\ipykernel_16572\\257147072.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[current_column_name] = df[prev_column_name].shift(1)\n"
     ]
    }
   ],
   "source": [
    "### Standard linear regression with 100 numeric features\n",
    "\n",
    "tsf100 = feature_creator_v1(ts_final, 100)\n",
    "tsf100 = tsf100.iloc[100:,:]\n",
    "df_train100, df_test100 = data_splitter(tsf100)\n",
    "y_train100 = df_train100['aqi_d0']\n",
    "X_train100 = df_train100.drop(columns_to_drop, axis=1)\n",
    "y_test100 = df_test100['aqi_d0']\n",
    "X_test100 = df_test100.drop(columns_to_drop, axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train100)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train100)\n",
    "X_test_scaled = scaler.transform(X_test100)\n",
    "\n",
    "lr_scaled = LinearRegression()\n",
    "lr_scaled.fit(X_train_scaled, y_train100)\n",
    "pred_train100 = lr_scaled.predict(X_train_scaled)\n",
    "pred_test100 = lr_scaled.predict(X_test_scaled)\n",
    "\n",
    "print('for TRAIN:')\n",
    "print('MSE:', MSE(y_train100, pred_train100))\n",
    "print('R2:', r2_score(y_train100, pred_train100))\n",
    "print('for TEST:')\n",
    "print('MSE:', MSE(y_test100, pred_test100))\n",
    "print('R2:', r2_score(y_test100, pred_test100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a9346fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross-validation for linear regression with 100 numeric features\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 10)\n",
    "rmse = []\n",
    "mae = []\n",
    "r2 = []\n",
    "rmse_dfm = []\n",
    "mae_dfm = []\n",
    "r2_dfm = []\n",
    "all_predictions = None\n",
    "aqi_mean = tsf100['aqi_d0'].mean()\n",
    "for train_index, test_index in tscv.split(tsf100):\n",
    "    cv_train, cv_test = tsf100.iloc[train_index], tsf100.iloc[test_index]\n",
    "    \n",
    "    y_cv_train = cv_train['aqi_d0']\n",
    "    X_cv_train = cv_train.drop('aqi_d0', axis=1)\n",
    "    y_cv_test = cv_test['aqi_d0']\n",
    "    X_cv_test = cv_test.drop('aqi_d0', axis=1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_cv_train)\n",
    "    \n",
    "    X_cv_train_scaled = scaler.transform(X_cv_train)\n",
    "    X_cv_test_scaled = scaler.transform(X_cv_test)\n",
    "    \n",
    "    lr_scaled = LinearRegression()\n",
    "    lr_scaled.fit(X_cv_train_scaled, y_cv_train )\n",
    "    predictions = lr_scaled.predict(X_cv_test_scaled)\n",
    " \n",
    "    rmse.append(np.sqrt(MSE(y_cv_test, predictions)))\n",
    "    mae.append(MAE(y_cv_test, predictions))\n",
    "    r2.append(r2_score(y_cv_test, predictions))\n",
    "\n",
    "    dfmean = pd.DataFrame(index=cv_test.index)\n",
    "    dfmean['aqi_d0'] = aqi_mean\n",
    "    \n",
    "    rmse_dfm.append(np.sqrt(MSE(y_cv_test, dfmean.values)))\n",
    "    mae_dfm.append(MAE(y_cv_test, dfmean.values))\n",
    "    r2_dfm.append(r2_score(y_cv_test, dfmean.values))\n",
    "\n",
    "\n",
    "rmse_df_mean = np.mean(rmse_dfm)\n",
    "rmse_mean = np.mean(rmse)\n",
    "\n",
    "mae_df_mean = np.mean(mae_dfm)\n",
    "mae_mean = np.mean(mae)\n",
    "\n",
    "r2_df_mean = np.mean(r2_dfm)\n",
    "r2_mean = np.mean(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b426404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean baseline:\n",
      "RMSE: 12.134831448276817\n",
      "MAE: 8.860987770375926\n",
      "R2 -0.06503923953351068\n",
      "\n",
      "Linear regression with 100 lag-features:\n",
      "RMSE: 10.027423257130128\n",
      "MAE: 7.40013383225579\n",
      "R2 0.27212223754528236\n"
     ]
    }
   ],
   "source": [
    "print('Mean baseline:')\n",
    "print('RMSE:', rmse_df_mean)\n",
    "print('MAE:', mae_df_mean)\n",
    "print('R2', r2_df_mean)\n",
    "print('')\n",
    "print('Linear regression with 100 lag-features:')\n",
    "print('RMSE:', rmse_mean)\n",
    "print('MAE:', mae_mean)\n",
    "print('R2', r2_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73186682",
   "metadata": {},
   "source": [
    "Чем больше lag-фичей мы используем, тем хуже становится R2 score, и тем выше становятся RMSE и MAE. Одна из возможных причин таких результатов, это то что мы используем значения индексов усредненные по дням, а не по часам. Возможно, в случае часовых AQI результаты были бы немного лучше. Но на данном этапе мы пока не будем создавать новый датасет с часовыми индексами, а продолжим работать на текущем датасете. Попробуем использовать полиномиальные фичи и Lasso-регрессию для датасета с 30 lag-фичами, возможно это позволит улучшить результаты предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ea8fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "badb990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for TRAIN:\n",
      "MSE: 96.46502926519346\n",
      "R2: 0.3924710861817393\n",
      "for TEST:\n",
      "MSE: 61.801754987897304\n",
      "R2: 0.25012128147969825\n"
     ]
    }
   ],
   "source": [
    "### Check prediction quality of basic Lasso-regression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train30)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train30)\n",
    "X_test_scaled = scaler.transform(X_test30)\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train_scaled, y_train30)\n",
    "pred_lasso_train30 = lasso.predict(X_train_scaled)\n",
    "pred_lasso_test30 = lasso.predict(X_test_scaled)\n",
    "\n",
    "print('for TRAIN:')\n",
    "print('MSE:', MSE(y_train30, pred_lasso_train30))\n",
    "print('R2:', r2_score(y_train30, pred_lasso_train30))\n",
    "print('for TEST:')\n",
    "print('MSE:', MSE(y_test30, pred_lasso_test30))\n",
    "print('R2:', r2_score(y_test30, pred_lasso_test30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad4aee",
   "metadata": {},
   "source": [
    "Тут практически то же самое что и для обычной регрессии. Добавим полиномиальные фичи и посмотрим улучшит ли это как-нибудь наши результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90a7c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pipeline for Lasso-regression with polynomial features\n",
    "\n",
    "pipeline_Lasso = Pipeline([('scaler', StandardScaler()),\n",
    "                           ('polyfeatures', PolynomialFeatures(degree = 2)),\n",
    "                           ('lasso', Lasso())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "271dae93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for TRAIN:\n",
      "MSE: 96.29653576592746\n",
      "R2: 0.3935322445452857\n",
      "for TEST:\n",
      "MSE: 61.99834915200721\n",
      "R2: 0.2477358835265142\n"
     ]
    }
   ],
   "source": [
    "### Check Lasso regression with polynomial features\n",
    "\n",
    "pipeline_Lasso.fit(X_train30, y_train30)\n",
    "pred_lasso_poly_train30 = pipeline_Lasso.predict(X_train30)\n",
    "pred_lasso_poly_test30 = pipeline_Lasso.predict(X_test30)\n",
    "\n",
    "print('for TRAIN:')\n",
    "print('MSE:', MSE(y_train30, pred_lasso_poly_train30))\n",
    "print('R2:', r2_score(y_train30, pred_lasso_poly_train30))\n",
    "print('for TEST:')\n",
    "print('MSE:', MSE(y_test30, pred_lasso_poly_test30))\n",
    "print('R2:', r2_score(y_test30, pred_lasso_poly_test30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435622d",
   "metadata": {},
   "source": [
    "Полиномиальные признаки никак не улучшили результаты предсказания. Напоследок проверим улучшится ли качество предсказания при использовании категориальных фичей для датасета с 30-ю lag-фичами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3df6cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsf30 = feature_creator_v2(ts_final, 30)\n",
    "tsf30 = tsf30.iloc[30:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43562da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['monthday', 'weekend']\n"
     ]
    }
   ],
   "source": [
    "### Check categorical features\n",
    "\n",
    "categorical_features = tsf30.select_dtypes(exclude='number').columns.tolist()\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2a3c53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aqi_d0', 'month', 'weekday', 'aqi_d1', 'aqi_d2', 'aqi_d3', 'aqi_d4', 'aqi_d5', 'aqi_d6', 'aqi_d7', 'aqi_d8', 'aqi_d9', 'aqi_d10', 'aqi_d11', 'aqi_d12', 'aqi_d13', 'aqi_d14', 'aqi_d15', 'aqi_d16', 'aqi_d17', 'aqi_d18', 'aqi_d19', 'aqi_d20', 'aqi_d21', 'aqi_d22', 'aqi_d23', 'aqi_d24', 'aqi_d25', 'aqi_d26', 'aqi_d27', 'aqi_d28', 'aqi_d29', 'aqi_d30']\n"
     ]
    }
   ],
   "source": [
    "### Check numeric features\n",
    "\n",
    "numerical_features = tsf30.select_dtypes(include='number').columns.tolist()\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6b3a18",
   "metadata": {},
   "source": [
    "Две категориальные фичи попали в числовые. Сконвертируем их в другой формат, а затем разделим выборку на train и test. А еще немного увеличим тестовую выборку, чтобы она включала все возможные категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4480001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb166a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare data for subsequent preproccessing\n",
    "\n",
    "tsf30['month'] = tsf30['month'].astype(str)\n",
    "tsf30['weekday'] = tsf30['weekday'].astype(str)\n",
    "\n",
    "df_train30, df_test30 = data_splitter_v2(tsf30)\n",
    "y_train30 = df_train30['aqi_d0']\n",
    "X_train30 = df_train30.drop(columns_to_drop, axis=1)\n",
    "y_test30 = df_test30['aqi_d0']\n",
    "X_test30 = df_test30.drop(columns_to_drop, axis=1)\n",
    "\n",
    "categorical_features = X_train30.select_dtypes(exclude='number').columns.tolist()\n",
    "numerical_features = X_train30.select_dtypes(include='number').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab617972",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create numeric and categorical pipelines\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[('scale', StandardScaler())])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[('one-hot', OneHotEncoder(handle_unknown='ignore', sparse=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "630c8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine both previously created pipelines into one\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_processor = ColumnTransformer(transformers=[('numeric', numeric_pipeline, numerical_features),\n",
    "                                                 ('categorical', categorical_pipeline, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "823b2c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for TRAIN:\n",
      "MSE: 96.04226664132453\n",
      "R2: 0.39263507881091897\n",
      "for TEST:\n",
      "MSE: 97.30865324545069\n",
      "R2: -0.01455529759846863\n"
     ]
    }
   ],
   "source": [
    "### Check prediction quality of Lasso with categorical features\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(full_processor.fit_transform(X_train30), y_train30)\n",
    "pred_lasso_train30 = lasso.predict(full_processor.fit_transform(X_train30))\n",
    "pred_lasso_test30 = lasso.predict(full_processor.fit_transform(X_test30))\n",
    "\n",
    "print('for TRAIN:')\n",
    "print('MSE:', MSE(y_train30, pred_lasso_train30))\n",
    "print('R2:', r2_score(y_train30, pred_lasso_train30))\n",
    "print('for TEST:')\n",
    "print('MSE:', MSE(y_test30, pred_lasso_test30))\n",
    "print('R2:', r2_score(y_test30, pred_lasso_test30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57baaea0",
   "metadata": {},
   "source": [
    "Стало только хуже. Наверное на этом можно закончить эксперименты с линейными моделями и перейти к более сложным моделям, так как маловероятно что здесь можно как-то существенным образом улучшить результаты. В качестве следующей модели возьмем Catboost. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf9fa2",
   "metadata": {},
   "source": [
    "Наилучшие результаты были получены для модели простой линейной регрессии с 10 lag-фичами без категориальных признаков:<br>\n",
    "RMSE: 9.604746175563356<br>\n",
    "MAE: 6.996398468789235<br>\n",
    "R2 0.3482510123808328<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8928f2cb",
   "metadata": {},
   "source": [
    "<a id='part_3'></a>\n",
    "## 3.Эксперименты с Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3e79b",
   "metadata": {},
   "source": [
    "[ВЕРНУТЬСЯ В НАЧАЛО](#part_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9acd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e929f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create timeseries with 30 lag-features and categorical features\n",
    "\n",
    "tsf30 = feature_creator_v2(ts_final, 30)\n",
    "tsf30['month'] = tsf30['month'].astype(str)\n",
    "tsf30['weekday'] = tsf30['weekday'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8193c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split data into train and test; also specify categorical columns\n",
    "\n",
    "df_train30, df_test30 = data_splitter_v2(tsf30)\n",
    "y_train30 = df_train30['aqi_d0']\n",
    "X_train30 = df_train30.drop(columns_to_drop, axis=1)\n",
    "y_test30 = df_test30['aqi_d0']\n",
    "X_test30 = df_test30.drop(columns_to_drop, axis=1)\n",
    "categorical_features_indices = np.where(X_train30.dtypes != float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4eeadcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize CatboostRegressor\n",
    "\n",
    "model = CatBoostRegressor(loss_function='RMSE',\n",
    "                           random_seed=25,\n",
    "                           logging_level='Silent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6e67370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ac979492b74f868fb708da43e35ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x2471a587af0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train CatboostRegressor\n",
    "\n",
    "model.fit(X_train30, y_train30,\n",
    "          cat_features=categorical_features_indices,\n",
    "          eval_set=(X_test30, y_test30),\n",
    "          #     logging_level='Verbose',  # you can uncomment this for text output\n",
    "          plot=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "737f7a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 8.285007842746582\n",
      "MAE: 5.950441980702406\n",
      "R2: 0.28433445556342474\n"
     ]
    }
   ],
   "source": [
    "### Check results of Catboost experiment\n",
    "\n",
    "preds = model.predict(X_test30)\n",
    "\n",
    "print('RMSE:', np.sqrt(MSE(y_test30, preds)))\n",
    "print('MAE:', MAE(y_test30, preds))\n",
    "print('R2:', r2_score(y_test30, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30862d17",
   "metadata": {},
   "source": [
    "К сожалению, чуда не случилось и catboost показывает примерно такие же результаты как и простая линейная регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72740158",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross-validation for Catboost with 30 numeric features and 4 categorical features\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 10)\n",
    "rmse = []\n",
    "mae = []\n",
    "r2 = []\n",
    "rmse_dfm = []\n",
    "mae_dfm = []\n",
    "r2_dfm = []\n",
    "all_predictions = None\n",
    "aqi_mean = tsf30['aqi_d0'].mean()\n",
    "for train_index, test_index in tscv.split(tsf30):\n",
    "    cv_train, cv_test = tsf30.iloc[train_index], tsf30.iloc[test_index]\n",
    "    \n",
    "    y_cv_train = cv_train['aqi_d0']\n",
    "    X_cv_train = cv_train.drop('aqi_d0', axis=1)\n",
    "    y_cv_test = cv_test['aqi_d0']\n",
    "    X_cv_test = cv_test.drop('aqi_d0', axis=1)\n",
    "    \n",
    "    model = CatBoostRegressor(loss_function='RMSE',\n",
    "                              random_seed=25,\n",
    "                              logging_level='Silent')\n",
    "\n",
    "    model.fit(X_cv_train, y_cv_train, cat_features=categorical_features_indices, eval_set=(X_cv_test, y_cv_test))\n",
    "    predictions = model.predict(X_cv_test)\n",
    " \n",
    "    rmse.append(np.sqrt(MSE(y_cv_test, predictions)))\n",
    "    mae.append(MAE(y_cv_test, predictions))\n",
    "    r2.append(r2_score(y_cv_test, predictions))\n",
    "\n",
    "    dfmean = pd.DataFrame(index=cv_test.index)\n",
    "    dfmean['aqi_d0'] = aqi_mean\n",
    "    \n",
    "    rmse_dfm.append(np.sqrt(MSE(y_cv_test, dfmean.values)))\n",
    "    mae_dfm.append(MAE(y_cv_test, dfmean.values))\n",
    "    r2_dfm.append(r2_score(y_cv_test, dfmean.values))\n",
    "\n",
    "\n",
    "rmse_df_mean = np.mean(rmse_dfm)\n",
    "rmse_mean = np.mean(rmse)\n",
    "\n",
    "mae_df_mean = np.mean(mae_dfm)\n",
    "mae_mean = np.mean(mae)\n",
    "\n",
    "r2_df_mean = np.mean(r2_dfm)\n",
    "r2_mean = np.mean(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c353988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean baseline:\n",
      "RMSE: 12.27240446713256\n",
      "MAE: 8.978707042397936\n",
      "R2 -0.05862792066997431\n",
      "\n",
      "Catboost with 30 numeric and 4 categorical features:\n",
      "RMSE: 9.66646053216206\n",
      "MAE: 7.0764718227070365\n",
      "R2 0.34738229879250104\n"
     ]
    }
   ],
   "source": [
    "print('Mean baseline:')\n",
    "print('RMSE:', rmse_df_mean)\n",
    "print('MAE:', mae_df_mean)\n",
    "print('R2', r2_df_mean)\n",
    "print('')\n",
    "print('Catboost with 30 numeric and 4 categorical features:')\n",
    "print('RMSE:', rmse_mean)\n",
    "print('MAE:', mae_mean)\n",
    "print('R2', r2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55b02585",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross-validation for Catboost with 30 numeric features\n",
    "\n",
    "tsf30 = feature_creator_v1(ts_final, 30)\n",
    "df_train30, df_test30 = data_splitter_v2(tsf30)\n",
    "y_train30 = df_train30['aqi_d0']\n",
    "X_train30 = df_train30.drop(columns_to_drop, axis=1)\n",
    "y_test30 = df_test30['aqi_d0']\n",
    "X_test30 = df_test30.drop(columns_to_drop, axis=1)\n",
    "categorical_features_indices = np.where(X_train30.dtypes != float)[0]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 10)\n",
    "rmse = []\n",
    "mae = []\n",
    "r2 = []\n",
    "rmse_dfm = []\n",
    "mae_dfm = []\n",
    "r2_dfm = []\n",
    "all_predictions = None\n",
    "aqi_mean = tsf30['aqi_d0'].mean()\n",
    "for train_index, test_index in tscv.split(tsf30):\n",
    "    cv_train, cv_test = tsf30.iloc[train_index], tsf30.iloc[test_index]\n",
    "    \n",
    "    y_cv_train = cv_train['aqi_d0']\n",
    "    X_cv_train = cv_train.drop('aqi_d0', axis=1)\n",
    "    y_cv_test = cv_test['aqi_d0']\n",
    "    X_cv_test = cv_test.drop('aqi_d0', axis=1)\n",
    "    \n",
    "    model = CatBoostRegressor(loss_function='RMSE',\n",
    "                              random_seed=25,\n",
    "                              logging_level='Silent')\n",
    "\n",
    "    model.fit(X_cv_train, y_cv_train, cat_features=categorical_features_indices, eval_set=(X_cv_test, y_cv_test))\n",
    "    predictions = model.predict(X_cv_test)\n",
    " \n",
    "    rmse.append(np.sqrt(MSE(y_cv_test, predictions)))\n",
    "    mae.append(MAE(y_cv_test, predictions))\n",
    "    r2.append(r2_score(y_cv_test, predictions))\n",
    "\n",
    "    dfmean = pd.DataFrame(index=cv_test.index)\n",
    "    dfmean['aqi_d0'] = aqi_mean\n",
    "    \n",
    "    rmse_dfm.append(np.sqrt(MSE(y_cv_test, dfmean.values)))\n",
    "    mae_dfm.append(MAE(y_cv_test, dfmean.values))\n",
    "    r2_dfm.append(r2_score(y_cv_test, dfmean.values))\n",
    "\n",
    "\n",
    "rmse_df_mean = np.mean(rmse_dfm)\n",
    "rmse_mean = np.mean(rmse)\n",
    "\n",
    "mae_df_mean = np.mean(mae_dfm)\n",
    "mae_mean = np.mean(mae)\n",
    "\n",
    "r2_df_mean = np.mean(r2_dfm)\n",
    "r2_mean = np.mean(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cabb4573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean baseline:\n",
      "RMSE: 12.27240446713256\n",
      "MAE: 8.978707042397936\n",
      "R2 -0.05862792066997431\n",
      "\n",
      "Catboost with 30 numeric features:\n",
      "RMSE: 9.797108923677888\n",
      "MAE: 7.183606290906108\n",
      "R2 0.330641396660838\n"
     ]
    }
   ],
   "source": [
    "print('Mean baseline:')\n",
    "print('RMSE:', rmse_df_mean)\n",
    "print('MAE:', mae_df_mean)\n",
    "print('R2', r2_df_mean)\n",
    "print('')\n",
    "print('Catboost with 30 numeric features:')\n",
    "print('RMSE:', rmse_mean)\n",
    "print('MAE:', mae_mean)\n",
    "print('R2', r2_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f0bc8",
   "metadata": {},
   "source": [
    "<a id='part_4'></a>\n",
    "## 4.Обсуждение и выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf10806",
   "metadata": {},
   "source": [
    "[ВЕРНУТЬСЯ В НАЧАЛО](#part_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22cc20b",
   "metadata": {},
   "source": [
    "Ниже приведено сравнение результатов кросс-валидации для простой линейной регрессии и Catboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef4f6d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table {align:left;display:block} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "table_css = 'table {align:left;display:block} '\n",
    "HTML('<style>{}</style>'.format(table_css))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52646488",
   "metadata": {},
   "source": [
    "Metrics |LinearRegression |Catboost with cat.features|Catboost numeric only|Mean Baseline|\n",
    "-----------|-----------|-----------|---------| ---------| \n",
    "RMSE|9.604746175563356|9.66646053216206|9.797108923677888| 12.27240446713256|\n",
    "MAE|6.996398468789235|7.0764718227070365|7.183606290906108| 8.978707042397936|\n",
    "R2 score|0.3482510123808328|0.34738229879250104|0.330641396660838| -0.05862792066997431|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724ab44",
   "metadata": {},
   "source": [
    "Результаты, полученные в ходе данных экспериментов сложно назвать удовлетворительными. В целом, как линейная регрессия, так и Catboost показали примерно одинаковые результаты. Одинаково плохие. К сожалению ни один из способов использованных в данной работе не помог существенным образом улучшить качество предсказания. И это можно объяснить несколькими причинами: <br>\n",
    "1) Мы использовали модели неспецифичные к временным рядам. В целом даже если смотреть публикации по Machine Learning за последние несколько лет, то в большинстве случаев для временных рядов используют либо специфичные к временным рядам модели, такие как ARIMA, либо Deep-Learning, либо еще реже - RandomForest и прочие модели(в том числе и бустинги). Причем в тех работах где используется Random Forest и бустинги обычно временные ряды \"обогащены\" дополнительными категориальными переменными (например температура, влажность, осадки, скорость ветра и т.д.). В нашей же работе категориальные фичи были получены из самого timeseries, что возможно и явилось причиной того, что их использование в случае линейной регрессии только ухудшало качество предсказания, а в случае Catboost лишь немного улучшило результаты.<br>\n",
    "2) В нашей работе для предсказания индекса AQI были использованы предыдущие индексы усредненные по дням. Не исключено, что в случае использования часовых индексов AQI мы могли бы добиться чуть более лучших результатов. А еще возможно стоило проверить предсказание индекса на текущий день не по предыдущим индексам, а по предыдущим измеренным концентрациям загрязнителей.<br>\n",
    "3) В данной работе практически никак не применялись методы обработки/подготовки данных специфичные для временных рядов. Полученный ряд не проверялся ни на автокорреляцию, ни на сезонность, ни на шумы. Вполне возможно, что дополнительная предобработка временного ряда могла бы немного улучшить результаты.<br>\n",
    "4) В рамках данной работы решалась в принципе наверное очень сложная (а может даже и невозможная) задача предсказания индекса AQI по предыдущим значениям AQI. Здесь не решалась более простая задача предсказания AQI по концентрациям загрязнителей (которую как раз таки вполне можно решить, особенно бустингом).<br>\n",
    "5) В качестве данных были взяты данные одной станции в Дании. Данная страна характеризуется относительно высоким уровнем качества воздуха. Возможно, в случае проведения экспериментов по измерениям станции расположенной в более загрязненном индустриальном городе, мы могли бы получить более качественную модель за счет более широкого диапазона AQI и более выраженных колебаний концентраций загрязнителей в зависимости от времени суток, дня недели, сезона, праздников и др.<br>\n",
    "<br>\n",
    "ВЫВОД: К сожалению, для поставленной задачи ни одна из использованных моделей не показала удовлетворительных результатов. Наилучший результат был получен на модели простой линейной регрессии. Возможно, что для последующих экспериментов целесообразнее/правильнее использовать модели Deep-Learning. Также вероятно что дополнительные данные, такие как например данные о погоде могли бы немного улучшить качество предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8a78b",
   "metadata": {},
   "source": [
    "# [ВВЕРХ](#part_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
