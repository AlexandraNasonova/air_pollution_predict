{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2279c3f5",
   "metadata": {},
   "source": [
    "Небольшой скрипт для быстрого создания датасета по данным выбранных стран, городов или станций. Использует данные, скачанные через модуль aqreport_loader написанный Александрой Насоновой. Скрипт сканирует текущую директорию, далее создает список всех csv файлов, вложенных в папку data. Далее полученный список файлов фильтруется исходя из заданных параметров одной из трех выбранных функций и итоговый short-list файлов объединяется в один единый датасет, который сохраняется в текущей директории. При запуске скрипта необходимо удостовериться, что текущая директория содержит файл с новыми метаданными и папку с исходными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7c928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28f8926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GI', 'NL', 'RS', 'LV', 'HU', 'XK', 'NO', 'CZ', 'ES', 'RO', 'EE', 'LT', 'PT', 'GR', 'GE', 'BG', 'CH', 'UA', 'FR', 'PL', 'DE', 'TR', 'ME', 'SE', 'FI', 'MT', 'GB', 'AL', 'SK', 'CY', 'AD', 'MK', 'IT', 'BA', 'BE', 'LU', 'AT', 'IS', 'IE', 'SI', 'DK', 'HR']\n"
     ]
    }
   ],
   "source": [
    "csv1 = glob.glob(os.getcwd() + '/data' + '/**/*.csv', recursive=True)\n",
    "codes = [] \n",
    "for file in csv1:\n",
    "    codes.append(file.split('\\\\')[-1][:2])\n",
    "codes = list(set(codes))\n",
    "print(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac2d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_by_country(*codes) -> None:  ### pass citycodes separated by comma\n",
    "    codelist = [*codes]\n",
    "    csv2 = []\n",
    "    for file in csv1:\n",
    "        for code in codelist:\n",
    "            if code in file:\n",
    "                csv2.append(file)\n",
    "    df = pd.concat([pd.read_csv(f) for f in csv2])\n",
    "    df.to_csv( \"df_\" + '_'.join(code for code in codelist) + \".csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d81c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_by_localid(*codes) -> None:  ### pass localcodes separated by comma\n",
    "    codelist = [*codes]\n",
    "    csv3 = []\n",
    "    for file in csv1:\n",
    "        if file.split('_')[2] in codelist:\n",
    "            csv3.append(file)\n",
    "    df = pd.concat([pd.read_csv(f) for f in csv3])\n",
    "    df.to_csv( \"df_\" + '_'.join(code for code in codelist) + \".csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca1e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_by_city(*names) -> None:     ### pass citynames separated by comma\n",
    "    dfm = pd.read_csv(\"final_metadata.csv\", low_memory=False)\n",
    "    citynames = [*names]\n",
    "    localids = []\n",
    "    csv4 = []\n",
    "    cities_lower = []\n",
    "    cities_regular = []\n",
    "    for city in list(dfm.query('StationCity==StationCity')['StationCity'].unique()):\n",
    "        cities_lower.append(city.lower().split(' ')[0])\n",
    "        cities_regular.append(city)\n",
    "    for i in range(len(cities_lower)):\n",
    "        for cityname in citynames:\n",
    "            if cityname.lower() in cities_lower[i]:\n",
    "                localids.extend(list(dfm[(dfm['StationCity']==cities_regular[i]) & (dfm['LocalCode'].notna())]['LocalCode'].unique()))                  \n",
    "    for ele in localids:\n",
    "        for file in csv1:\n",
    "            if int(ele) == int(file.split('_')[2]):\n",
    "                csv4.append(file)\n",
    "    df = pd.concat([pd.read_csv(f) for f in csv4])\n",
    "    df.to_csv( \"df_\" + '_'.join(cityname for citynames in citynames) + \".csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ca14e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_by_country('DK', 'RS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344553bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_by_city('Paris')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
