{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db573760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616ef178",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a list of all csv files in our data folder\n",
    "\n",
    "csv1 = glob.glob(os.getcwd() + '/data' + '/**/*.csv', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af606fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a dictionary containing local codes and corresponding csv files\n",
    "\n",
    "stat_dict = {}\n",
    "for file in csv1:\n",
    "    stat_dict[int(file.split('_')[-3])] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b948576",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create dataframe from all csv files, add local_codes, then drop duplicates so that only unique stations remain\n",
    "\n",
    "df = pd.concat([pd.read_csv(f, nrows=1) for f in list(stat_dict.values())])\n",
    "local_code_list = []\n",
    "for i in range(len(list(stat_dict.values()))):\n",
    "    local_code_list.append(list(stat_dict.values())[i].split('_')[-3])\n",
    "df['local_code'] = local_code_list\n",
    "df.drop_duplicates(['AirQualityStation'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9058aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Steps to prepare merged_metadata from PanEuropean and AirBase_v8 files\n",
    "### Metadata information is combined, leaving only one row per unique station\n",
    "\n",
    "# df_meta = pd.read_csv('PanEuropean_metadata.csv', sep=\"\\t\")\n",
    "# df_stat = pd.read_csv('AirBase_v8_stations.csv', sep=\"\\t\")\n",
    "# drop_list2 = ['Countrycode','Timezone','Namespace','AirQualityNetwork','AirQualityStationNatCode','SamplingPoint','SamplingProces','Sample','AirPollutantCode','ObservationDateBegin','ObservationDateEnd','Projection','Altitude','MeasurementType','EquivalenceDemonstrated','MeasurementEquipment','InletHeight','BuildingDistance','KerbDistance']\n",
    "# drop_list3 = ['station_local_code','type_of_station','station_ozone_classification','station_type_of_area','station_subcat_rural_back','street_type','station_longitude_deg','station_latitude_deg','station_altitude','lau_level1_code','lau_level2_code','lau_level2_name','EMEP_station']\n",
    "# df_meta.drop(columns=drop_list2, inplace=True)\n",
    "# df_stat.drop(columns=drop_list3, inplace=True)\n",
    "# df_meta.drop_duplicates(subset='AirQualityStation', keep='first', inplace=True)\n",
    "# df_stat.drop_duplicates(subset='station_european_code', keep='first', inplace=True)\n",
    "# df_stat.rename(columns = {'station_european_code':'AirQualityStationEoICode',\n",
    "#                           'country_iso_code':'Countrycode',\n",
    "#                           'country_name':'CountryName',\n",
    "#                           'station_name':'StationName',\n",
    "#                           'station_start_date':'StationStartDate',\n",
    "#                           'station_end_date':'StationEndDate',\n",
    "#                           'station_city':'StationCity'}, inplace = True)\n",
    "# meta = df_meta.merge(df_stat, on='AirQualityStationEoICode', how='left')\n",
    "# meta.to_csv( \"merged_metadata.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c78eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load previously created merged_metadata (PanEuropean merged with AirBase_v8 containing only unique stations)\n",
    "\n",
    "metadata = pd.read_csv(\"merged_metadata.csv\")\n",
    "metadata = metadata.reset_index().rename(columns={'index': 'LocalCode'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dadd69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add local_code to merged_metadata then prepare it for subsequent merge with PanEuropean\n",
    "\n",
    "new_meta = metadata.merge(df, on='AirQualityStation', how='left')\n",
    "new_meta['LocalCode'] = new_meta['local_code']\n",
    "new_meta.drop(columns=['local_code'], inplace=True)\n",
    "new_meta = new_meta.loc[:, ['LocalCode', 'AirQualityStation', 'CountryName', 'StationName', \\\n",
    "                            'StationStartDate', 'StationEndDate', 'StationCity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6e3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge PanEuropean with previously created metadata to create a final full metadata file\n",
    "\n",
    "PanEuropean_metadata = pd.read_csv('PanEuropean_metadata.csv', sep=\"\\t\")\n",
    "new_meta_full = PanEuropean_metadata.merge(new_meta, on='AirQualityStation', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce0b4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export final metadata file\n",
    "\n",
    "new_meta_full.to_csv(\"final_metadata.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
